{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c009b16-630b-4c6c-8c63-89619ed87334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6685a29f-b1d9-460b-b2aa-83e161f5a084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/29 13:42:49 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"hw_basics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca08d73c-3684-441b-b17f-b44104203b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Disabled automatic broadcast join with spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b3e1f5-828e-4a2f-a345-6aba396ab6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://06b6f1883283:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x72eb240e2a00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939bcb0f-d824-45e3-9853-cc777c708b00",
   "metadata": {},
   "source": [
    "# Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176bcaaf-805d-46cc-b9d6-c6f08ef5df97",
   "metadata": {},
   "source": [
    "\n",
    "* match_details\n",
    "    * a row for every players performance in a match\n",
    "* matches\n",
    "    * a row for every match\n",
    "* medals_matches_players\n",
    "    * a row for every medal type a player gets in a match\n",
    "* medals\n",
    "    * a row for every medal type\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c304cb-59e8-4513-8c90-e2815f9f34b5",
   "metadata": {},
   "source": [
    "# Data Lodaing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "185614b1-b159-47e3-bdf2-f95bc92444f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/iceberg/notebooks/notebooks/homework\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed5b44a5-7333-4bed-a500-9ca6ff0ac9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devices.csv  maps.csv\t\tmatches.csv  medals_matches_players.csv\n",
      "events.csv   match_details.csv\tmedals.csv\n"
     ]
    }
   ],
   "source": [
    "!ls /home/iceberg/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f08f0da-5ea6-40e9-ba53-ccbcef13c66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_id,mapid,is_team_game,playlist_id,game_variant_id,is_match_over,completion_date,match_duration,game_mode,map_variant_id\n",
      "11de1a94-8d07-4162-9f5f-d3cc753c811c,c7edbf0f-f206-11e4-aa52-24be05e24f7e,true,f72e0ef0-7c4a-4307-af78-8e38dac3fdba,1e473914-46e4-408d-af26-178fb115de76,true,2016-02-22 00:00:00.000000,,,\n",
      "d3643e71-3e51-43e6-a200-f4a7f306ac12,cb914b9e-f206-11e4-b447-24be05e24f7e,false,d0766624-dbd7-4536-ba39-2d890a6143a9,257a305e-4dd3-41f1-9824-dfe7e8bd59e1,true,2016-02-14 00:00:00.000000,,,\n"
     ]
    }
   ],
   "source": [
    "!head -n 3 /home/iceberg/data/matches.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c68e06-7b62-448a-ae55-6d0b14f60fb3",
   "metadata": {},
   "source": [
    "`NOTE:` We are inside the docker ecosystem which has minio, spark-iceberg, mc inside it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb660283-a759-499e-a583-c6e1842a23d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "matches = spark.read\\\n",
    "              .option(\"header\", \"true\")\\\n",
    "              .csv(\"/home/iceberg/data/matches.csv\")  # the path where the file is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c48d3194-4d71-44cc-8ac0-09c37df5d08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[match_id: string, mapid: string, is_team_game: string, playlist_id: string, game_variant_id: string, is_match_over: string, completion_date: string, match_duration: string, game_mode: string, map_variant_id: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc2196b2-0cdf-460e-b5d2-e1edda67a8c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+--------------------+--------------------+-------------+--------------------+--------------+---------+--------------------+\n",
      "|            match_id|               mapid|is_team_game|         playlist_id|     game_variant_id|is_match_over|     completion_date|match_duration|game_mode|      map_variant_id|\n",
      "+--------------------+--------------------+------------+--------------------+--------------------+-------------+--------------------+--------------+---------+--------------------+\n",
      "|11de1a94-8d07-416...|c7edbf0f-f206-11e...|        true|f72e0ef0-7c4a-430...|1e473914-46e4-408...|         true|2016-02-22 00:00:...|          NULL|     NULL|                NULL|\n",
      "|d3643e71-3e51-43e...|cb914b9e-f206-11e...|       false|d0766624-dbd7-453...|257a305e-4dd3-41f...|         true|2016-02-14 00:00:...|          NULL|     NULL|                NULL|\n",
      "|d78d2aae-36e4-48a...|c7edbf0f-f206-11e...|        true|f72e0ef0-7c4a-430...|1e473914-46e4-408...|         true|2016-03-24 00:00:...|          NULL|     NULL|55e5ee2e-88df-465...|\n",
      "+--------------------+--------------------+------------+--------------------+--------------------+-------------+--------------------+--------------+---------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matches.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c27bc485-0690-44df-abc9-1cf70aa868ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_details = spark.read\\\n",
    "                      .option(\"header\", \"true\")\\\n",
    "                      .csv(\"/home/iceberg/data/match_details.csv\")  # the path where the file is present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "365adaf0-080f-46c5-aa05-e16a3e02a642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[match_id: string, player_gamertag: string, previous_spartan_rank: string, spartan_rank: string, previous_total_xp: string, total_xp: string, previous_csr_tier: string, previous_csr_designation: string, previous_csr: string, previous_csr_percent_to_next_tier: string, previous_csr_rank: string, current_csr_tier: string, current_csr_designation: string, current_csr: string, current_csr_percent_to_next_tier: string, current_csr_rank: string, player_rank_on_team: string, player_finished: string, player_average_life: string, player_total_kills: string, player_total_headshots: string, player_total_weapon_damage: string, player_total_shots_landed: string, player_total_melee_kills: string, player_total_melee_damage: string, player_total_assassinations: string, player_total_ground_pound_kills: string, player_total_shoulder_bash_kills: string, player_total_grenade_damage: string, player_total_power_weapon_damage: string, player_total_power_weapon_grabs: string, player_total_deaths: string, player_total_assists: string, player_total_grenade_kills: string, did_win: string, team_id: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4623c9f-b008-4c62-adfb-b0d335272862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/29 13:43:00 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+---------------------+------------+-----------------+--------+-----------------+------------------------+------------+---------------------------------+-----------------+----------------+-----------------------+-----------+--------------------------------+----------------+-------------------+---------------+-------------------+------------------+----------------------+--------------------------+-------------------------+------------------------+-------------------------+---------------------------+-------------------------------+--------------------------------+---------------------------+--------------------------------+-------------------------------+-------------------+--------------------+--------------------------+-------+-------+\n",
      "|            match_id|player_gamertag|previous_spartan_rank|spartan_rank|previous_total_xp|total_xp|previous_csr_tier|previous_csr_designation|previous_csr|previous_csr_percent_to_next_tier|previous_csr_rank|current_csr_tier|current_csr_designation|current_csr|current_csr_percent_to_next_tier|current_csr_rank|player_rank_on_team|player_finished|player_average_life|player_total_kills|player_total_headshots|player_total_weapon_damage|player_total_shots_landed|player_total_melee_kills|player_total_melee_damage|player_total_assassinations|player_total_ground_pound_kills|player_total_shoulder_bash_kills|player_total_grenade_damage|player_total_power_weapon_damage|player_total_power_weapon_grabs|player_total_deaths|player_total_assists|player_total_grenade_kills|did_win|team_id|\n",
      "+--------------------+---------------+---------------------+------------+-----------------+--------+-----------------+------------------------+------------+---------------------------------+-----------------+----------------+-----------------------+-----------+--------------------------------+----------------+-------------------+---------------+-------------------+------------------+----------------------+--------------------------+-------------------------+------------------------+-------------------------+---------------------------+-------------------------------+--------------------------------+---------------------------+--------------------------------+-------------------------------+-------------------+--------------------+--------------------------+-------+-------+\n",
      "|71d79b23-4143-435...|      taterbase|                    5|           5|            12537|   13383|                1|                       3|           0|                               98|             NULL|               2|                      3|          0|                              26|            NULL|                  4|          false|        PT14.81149S|                 6|                     4|                       255|                       28|                       0|                        0|                          0|                              0|                               0|                          0|                               0|                              0|                 13|                   1|                         0|      1|      1|\n",
      "|71d79b23-4143-435...| SuPeRSaYaInG0D|                   18|          18|           131943|  132557|                2|                       3|           0|                                2|             NULL|               1|                      3|          0|                              76|            NULL|                  7|          false|      PT11.2990845S|                 7|                     3|        350.58792304992676|                       49|                       1|                       45|                          0|                              0|                               0|                          0|                               0|                              0|                 18|                   2|                         0|      0|      0|\n",
      "|71d79b23-4143-435...|       EcZachly|                   21|          21|           168811|  169762|                2|                       5|           0|                               94|             NULL|               3|                      5|          0|                              24|            NULL|                  3|          false|      PT19.1357063S|                12|                    12|                       625|                       43|                       0|                        0|                          0|                              0|                               0|                          0|                               0|                              0|                 10|                   4|                         0|      1|      1|\n",
      "+--------------------+---------------+---------------------+------------+-----------------+--------+-----------------+------------------------+------------+---------------------------------+-----------------+----------------+-----------------------+-----------+--------------------------------+----------------+-------------------+---------------+-------------------+------------------+----------------------+--------------------------+-------------------------+------------------------+-------------------------+---------------------------+-------------------------------+--------------------------------+---------------------------+--------------------------------+-------------------------------+-------------------+--------------------+--------------------------+-------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match_details.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82d4daff-827e-4eb5-a467-cebe76add038",
   "metadata": {},
   "outputs": [],
   "source": [
    "medals_matches_players = spark.read\\\n",
    "\t\t\t\t              .option(\"header\", \"true\")\\\n",
    "\t\t\t\t              .csv(\"/home/iceberg/data/medals_matches_players.csv\")  # the path where the file is present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaf53230-adea-4477-81b9-92e49538d5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[match_id: string, player_gamertag: string, medal_id: string, count: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medals_matches_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "122125dc-9129-4922-bf1d-4541bd8dac4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+----------+-----+\n",
      "|            match_id|player_gamertag|  medal_id|count|\n",
      "+--------------------+---------------+----------+-----+\n",
      "|009fdac5-e15c-47c...|       EcZachly|3261908037|    7|\n",
      "|009fdac5-e15c-47c...|       EcZachly| 824733727|    2|\n",
      "|009fdac5-e15c-47c...|       EcZachly|2078758684|    2|\n",
      "+--------------------+---------------+----------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medals_matches_players.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1283952d-a05b-4827-8766-1b16a2640e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "medals = spark.read\\\n",
    "              .option(\"header\", \"true\")\\\n",
    "              .csv(\"/home/iceberg/data/medals.csv\")  # the path where the file is present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c7756a9-0499-435b-8e6b-6a6c74303a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[medal_id: string, sprite_uri: string, sprite_left: string, sprite_top: string, sprite_sheet_width: string, sprite_sheet_height: string, sprite_width: string, sprite_height: string, classification: string, description: string, name: string, difficulty: string]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24ef90f7-4d12-47f0-8a66-bfae24c5f1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----------+----------+------------------+-------------------+------------+-------------+--------------+--------------------+-------------+----------+\n",
      "|  medal_id|          sprite_uri|sprite_left|sprite_top|sprite_sheet_width|sprite_sheet_height|sprite_width|sprite_height|classification|         description|         name|difficulty|\n",
      "+----------+--------------------+-----------+----------+------------------+-------------------+------------+-------------+--------------+--------------------+-------------+----------+\n",
      "|2315448068|                NULL|       NULL|      NULL|              NULL|               NULL|        NULL|         NULL|          NULL|                NULL|         NULL|      NULL|\n",
      "|3565441934|                NULL|       NULL|      NULL|              NULL|               NULL|        NULL|         NULL|          NULL|                NULL|         NULL|      NULL|\n",
      "|4162659350|https://content.h...|        750|       750|                74|                 74|        1125|          899|      Breakout|Kill the last ene...|Buzzer Beater|        45|\n",
      "+----------+--------------------+-----------+----------+------------------+-------------------+------------+-------------+--------------+--------------------+-------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medals.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e2a7249-b603-440d-8fe6-115adadc3b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = spark.read\\\n",
    "              .option(\"header\", \"true\")\\\n",
    "              .csv(\"/home/iceberg/data/maps.csv\")  # the path where the file is present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00c7b2f0-5375-4692-b2ff-624101fe4052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[medal_id: string, sprite_uri: string, sprite_left: string, sprite_top: string, sprite_sheet_width: string, sprite_sheet_height: string, sprite_width: string, sprite_height: string, classification: string, description: string, name: string, difficulty: string]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b07713f-990e-44d6-8d61-2c649d2b9648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+\n",
      "|               mapid|               name|         description|\n",
      "+--------------------+-------------------+--------------------+\n",
      "|c93d708f-f206-11e...|              Urban|Andesia was the c...|\n",
      "|cb251c51-f206-11e...|     Raid on Apex 7|This unbroken rin...|\n",
      "|c854e54f-f206-11e...|March on Stormbreak|                NULL|\n",
      "+--------------------+-------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maps.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ce9f212-1af7-43fb-a8ec-8d24ab181b5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o131.saveAsTable.\n: org.apache.iceberg.exceptions.NoSuchTableException: Invalid table identifier: bucketed_matches\n\tat org.apache.iceberg.rest.RESTSessionCatalog.checkIdentifierIsValid(RESTSessionCatalog.java:981)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.access$100(RESTSessionCatalog.java:111)\n\tat org.apache.iceberg.rest.RESTSessionCatalog$Builder.<init>(RESTSessionCatalog.java:621)\n\tat org.apache.iceberg.rest.RESTSessionCatalog$Builder.<init>(RESTSessionCatalog.java:611)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.buildTable(RESTSessionCatalog.java:431)\n\tat org.apache.iceberg.catalog.BaseSessionCatalog$AsCatalog.buildTable(BaseSessionCatalog.java:84)\n\tat org.apache.iceberg.rest.RESTCatalog.buildTable(RESTCatalog.java:112)\n\tat org.apache.iceberg.CachingCatalog$CachingTableBuilder.<init>(CachingCatalog.java:219)\n\tat org.apache.iceberg.CachingCatalog$CachingTableBuilder.<init>(CachingCatalog.java:214)\n\tat org.apache.iceberg.CachingCatalog.buildTable(CachingCatalog.java:211)\n\tat org.apache.iceberg.spark.SparkCatalog.newBuilder(SparkCatalog.java:1006)\n\tat org.apache.iceberg.spark.SparkCatalog.stageCreate(SparkCatalog.java:260)\n\tat org.apache.spark.sql.connector.catalog.StagingTableCatalog.stageCreate(StagingTableCatalog.java:93)\n\tat org.apache.spark.sql.execution.datasources.v2.AtomicCreateTableAsSelectExec.run(WriteToDataSourceV2Exec.scala:120)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:634)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:564)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmatches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucketBy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmatch_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msortBy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmatch_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaveAsTable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbucketed_matches\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/readwriter.py:1586\u001b[0m, in \u001b[0;36mDataFrameWriter.saveAsTable\u001b[0;34m(self, name, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1585\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m-> 1586\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaveAsTable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o131.saveAsTable.\n: org.apache.iceberg.exceptions.NoSuchTableException: Invalid table identifier: bucketed_matches\n\tat org.apache.iceberg.rest.RESTSessionCatalog.checkIdentifierIsValid(RESTSessionCatalog.java:981)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.access$100(RESTSessionCatalog.java:111)\n\tat org.apache.iceberg.rest.RESTSessionCatalog$Builder.<init>(RESTSessionCatalog.java:621)\n\tat org.apache.iceberg.rest.RESTSessionCatalog$Builder.<init>(RESTSessionCatalog.java:611)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.buildTable(RESTSessionCatalog.java:431)\n\tat org.apache.iceberg.catalog.BaseSessionCatalog$AsCatalog.buildTable(BaseSessionCatalog.java:84)\n\tat org.apache.iceberg.rest.RESTCatalog.buildTable(RESTCatalog.java:112)\n\tat org.apache.iceberg.CachingCatalog$CachingTableBuilder.<init>(CachingCatalog.java:219)\n\tat org.apache.iceberg.CachingCatalog$CachingTableBuilder.<init>(CachingCatalog.java:214)\n\tat org.apache.iceberg.CachingCatalog.buildTable(CachingCatalog.java:211)\n\tat org.apache.iceberg.spark.SparkCatalog.newBuilder(SparkCatalog.java:1006)\n\tat org.apache.iceberg.spark.SparkCatalog.stageCreate(SparkCatalog.java:260)\n\tat org.apache.spark.sql.connector.catalog.StagingTableCatalog.stageCreate(StagingTableCatalog.java:93)\n\tat org.apache.spark.sql.execution.datasources.v2.AtomicCreateTableAsSelectExec.run(WriteToDataSourceV2Exec.scala:120)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:634)\n\tat org.apache.spark.sql.DataFrameWriter.saveAsTable(DataFrameWriter.scala:564)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "matches.write\\\n",
    "    .bucketBy(16, \"match_id\")\\\n",
    "    .sortBy(\"match_id\")\\\n",
    "    .saveAsTable(\"bucketed_matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2827af-2ffd-4e22-99d3-ee4c322b0db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_details.write\\\n",
    "    .bucketBy(16, \"match_id\")\\\n",
    "    .sortBy(\"match_id\")\\\n",
    "    .saveAsTable(\"bucketed_match_details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af647f8-42f3-4209-9726-990918196b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "medals_matches_players.write\\\n",
    "    .bucketBy(16, \"match_id\")\\\n",
    "    .sortBy(\"match_id\")\\\n",
    "    .saveAsTable(\"bucketed_medals_matches_players\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
